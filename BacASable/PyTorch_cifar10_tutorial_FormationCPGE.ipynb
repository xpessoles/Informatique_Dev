{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_cifar10_tutorial_FormationCPGE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xpessoles/Informatique_Dev/blob/master/PyTorch_cifar10_tutorial_FormationCPGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4zsDWUk5cavn"
      },
      "source": [
        "# Deep Learning pour la Classification d'Images\n",
        "\n",
        "**Dans ce notebook, vous allez**:\n",
        "- Apprendre les bases de PyTorch, un progiciel puissant mais facile à utiliser pour le calcul scientifique (et le deep learning)\n",
        "- Apprendre à créer et à paramétrer un réseau de neurones de convolution pour la classification des images.\n",
        "\n",
        "## Preliminaires\n",
        "\n",
        "Le commandes suivantes définissent des fonctions d'affichage et importent les fonctions nécessaires au tutoriel. Exécutez simplement la cellule avant de débuter le tutoriel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnee2WPudA9K"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Python 2/3 compatibility\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Colors from Colorbrewer Paired_12\n",
        "colors = [[31, 120, 180], [51, 160, 44]]\n",
        "colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    \"\"\"\n",
        "    :param img: (PyTorch Tensor)\n",
        "    \"\"\"\n",
        "    # unnormalize\n",
        "    img = img / 2 + 0.5     \n",
        "    # Convert tensor to numpy array\n",
        "    npimg = img.numpy()\n",
        "    # Color channel first -> color channel last\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "\n",
        "def plot_losses(train_history, val_history):\n",
        "    x = np.arange(1, len(train_history) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n",
        "    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"Evolution of the training and validation loss\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    :param cm: (numpy matrix) confusion matrix\n",
        "    :param classes: [str]\n",
        "    :param normalize: (bool)\n",
        "    :param title: (str)\n",
        "    :param cmap: (matplotlib color map)\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        \n",
        "    plt.figure(figsize=(8, 8))   \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aH_K9V7icav6"
      },
      "source": [
        "# I. Qu'est-ce que PyTorch ?\n",
        "\n",
        "C'est une bibliothèque de calcul scientifique en Python avec deux objectif principaux:\n",
        "\n",
        "- Replacer Numpy (la bibliothèque de calcul numérique de python) pour permettre l'exploitation des GPUs (processeurs de cartes graphiques)\n",
        "- Fournir une plateforme de recheche pour le deep learning efficace et simple à utiliser\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6RvPibnScawC"
      },
      "source": [
        "## 1. Tenseurs PyTorch \n",
        "\n",
        "Un tenseur (`torch.Tensor`) est une matrice multi-dimensionelle contenant des données de même type.\n",
        "\n",
        "Les `Tensor` sont similaires aux `ndarrays` de numpy, mais ils peuvent être utilisés pour du calcul sur GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "QcJgJQERcawQ"
      },
      "source": [
        "### Tensor Shape\n",
        "\n",
        "Pour connaître la forme d'un tenseur donné, vous pouvez utiliser la méthode `.size ()` (l'équivalent numpy est `.shape`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SI96-W9acawS",
        "outputId": "66183f3d-e0ab-40f1-d03f-ebab325bac64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "# Import torch and create the alias \"th\"\n",
        "# instead of writing torch.name_of_a_method() , we only need to write th.name_of_a_method()\n",
        "# (similarly to numpy imported as np)\n",
        "import torch as th\n",
        "\n",
        "# Create tensor of ones (FloatTensor by default)\n",
        "ones = th.ones(3, 2)\n",
        "print(ones)\n",
        "\n",
        "\n",
        "# Display the shape of a tensor\n",
        "# it can be used as a tuple\n",
        "print(\"Tensor Shape: {}\".format(ones.size()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "Tensor Shape: torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "pUPWrNarcawZ"
      },
      "source": [
        "### Reshape tensors\n",
        "\n",
        "Pour remodeler les tenseurs (par exemple, aplatir un tenseur 3D en un tableau 1D), vous pouvez utiliser la méthode `.view ()`:\n",
        "\n",
        "- **x.view(new_shape)**: renvoie un nouveau tenseur avec les mêmes données mais une taille différente. C'est l'équivalent de la fonction numpy * reshape * (Donne une nouvelle forme à un tableau sans changer ses données.). Vous pouvez lire la documentation complète [ici.](Http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "[ATTENTION] lorsque vous spécifiez une nouvelle forme, vous devez vous assurer que le nombre d'éléments est constant. Par exemple, une matrice 2D de taille 3x3 ne peut être vue que comme un tableau 1D de taille $ 3 x 3 = 9 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vX-oxI6Vcawb",
        "outputId": "744040a0-9540-4699-b195-c1554037bc40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Create a 3D tensor of size 3x2x2\n",
        "zeros_3d_tensor = th.zeros(3, 2, 2)\n",
        "print(\"Original size:\", zeros_3d_tensor.size())\n",
        "\n",
        "# Reshape it to a 1D array of size 3*2*2 = 12\n",
        "zeros_1d_array = zeros_3d_tensor.view(3 * 2 * 2)\n",
        "print(\"Reshaped tensor:\", zeros_1d_array.size())\n",
        "\n",
        "\n",
        "# Let's view our original tensor as a 2D matrix\n",
        "# If you want PyTorch to guess one remaining dimension,\n",
        "# you specify '-1' instead of the actual size\n",
        "zeros_2d_matrix = zeros_3d_tensor.view(-1, 2 * 2)\n",
        "\n",
        "print(\"Matrix shape:\", zeros_2d_matrix.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original size: torch.Size([3, 2, 2])\n",
            "Reshaped tensor: torch.Size([12])\n",
            "Matrix shape: torch.Size([3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kTO_FFswcawj"
      },
      "source": [
        "### Opérations de base sur les tensors\n",
        "\n",
        "Le tenseur prend en charge toutes les opérations de base d’algèbre linéaire. Vous pouvez lire la documentation complète [ici](http://pytorch.org/docs/master/tensors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ay7LvYeVcawl",
        "outputId": "37d04108-983b-433b-ac79-1cb7daf78230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "2 * ones + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OD7ZOT4jcaws"
      },
      "source": [
        "Les tenseurs PyTorch supportent également l'indexation numpy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "srzDzj_ocawu",
        "outputId": "c312e4d9-0940-47dd-e4ff-cd3440970f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"\\n Indexing Demo:\")\n",
        "print(ones[:, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Indexing Demo:\n",
            "tensor([1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "xrjqKguqcaw0"
      },
      "source": [
        "## 2. Pont avec Numpy\n",
        "AVERTISSEMENT: les tenseurs PyTorch sont différents des tableaux numpy\n",
        "même s'ils ont beaucoup en commun\n",
        "\n",
        "Cependant, il est facile avec PyTorch de transformer des tableaux Tenseurs en tableaux Numpy et vice versa:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gVAntrTVcaw3"
      },
      "source": [
        "### Numpy <-> PyTorch\n",
        "\n",
        "La création des tenseurs PyTorch à partir du tableau numpy se fait via la fonction `torch.from_numpy ()` (ici `th.from_numpy ()` car nous avons renommé *torch* en *th*)\n",
        "\n",
        "Pour transformer un tenseur PyTorch en un tableau numpy, vous pouvez simplement appeler la méthode `.numpy ()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "t2ENcAKOcaw5",
        "outputId": "7aedad62-1f1e-4e89-d114-31afb3841d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# np.float32 -> th.FloatTensor\n",
        "ones_matrix = np.ones((2, 2), dtype=np.float32)\n",
        "\n",
        "# the matrix is passed by reference:\n",
        "# if we modify the original numpy array, the tensor is also edited\n",
        "ones_tensor = th.from_numpy(ones_matrix)\n",
        "# Convert back to a numpy matrix\n",
        "numpy_matrix = ones_tensor.numpy()\n",
        "\n",
        "print(\"PyTorch Tensor:\")\n",
        "print(ones_tensor)\n",
        "\n",
        "print(\"Numpy Matrix:\")\n",
        "print(numpy_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Tensor:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "Numpy Matrix:\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Y0Itjyg-caxD"
      },
      "source": [
        "## 3. Différentiation Automatique\n",
        "\n",
        "Les tenseurs de Pytorch permettent de **calculer automatiquement les gradients**. Cela est particulièrement utile pour la rétropropagation.\n",
        "\n",
        "Une fois que vous avez terminé votre calcul, vous pouvez appeler `.backward()` et faire en sorte que tous les gradients soient calculés automatiquement.\n",
        "\n",
        "Vous pouvez accéder au gradient par rapport à une variable en utilisant `.grad`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IEZDUibxcaxj"
      },
      "source": [
        "Pour illustrer l’utilisation des `Variable` PyTorch,\n",
        "définissons une simple transformation linéaire d'une variable $x$:\n",
        "$$y = a \\cdot x + b$$\n",
        "\n",
        "PyTorch nous permet de calculer automatiquement $$ \\frac{dy}{dx} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "A4j85JjZcaxl",
        "outputId": "9ae27c8d-c576-424a-bf4e-7915f18c9bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create a tensor and tell PyTorch\n",
        "# that we want to compute the gradient\n",
        "# We need to specify that we want to compute the gradient\n",
        "# as it requires extra memory and computation\n",
        "\n",
        "x = th.ones(1, requires_grad=True)\n",
        "\n",
        "# Transformation constants\n",
        "a = 2\n",
        "b = 5\n",
        "\n",
        "# Define the tranformation and store the result\n",
        "# in a new variable\n",
        "y = a * x + b\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([7.], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_mxnlvwxcaxq"
      },
      "source": [
        "Calculons les gradients :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "X1i-pN-Fcaxs"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "skgIGZdmcaxw"
      },
      "source": [
        "`x.grad` contient le gradient:\n",
        "\n",
        "$$\\frac{dy}{dx} = a$$\n",
        "\n",
        "puisque $y = a \\cdot x + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_TYbuwsXcaxx",
        "outputId": "4087b8ef-075c-4bc6-a676-f17c5169adf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ggu-PBGvcax3"
      },
      "source": [
        "Vous pouvez maintenant changer les valeurs de $ a $ et $ b $ pour voir leurs effets sur le gradient (et constater que `x.grad` ne dépend que de la valeur de `a`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8iPn0C59cax5"
      },
      "source": [
        "## 4. PyTorch et les GPU (support CUDA)\n",
        "\n",
        "Google colab fournit un processeur graphique compatible CUDA, nous allons donc utiliser ses capacités. Vous pouvez déplacer le tenseur vers le GPU en utilisant simplement la méthode `to()`. Sinon, PyTorch utilisera le processeur.\n",
        "\n",
        "Ici, nous allons démontrer l’utilité du GPU sur une simple multiplication de matrice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwF6ePTpeefQ",
        "outputId": "24ec1e51-4804-40e3-8770-a6bc45ea963c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import time\n",
        "\n",
        "if th.cuda.is_available():\n",
        "  # Create tensors\n",
        "  x = th.ones(1000, 1000)\n",
        "  y = 2 * x + 3\n",
        "  # Do the calculation on cpu (default)\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_cpu = time.time() - start_time\n",
        "  \n",
        "  # Do the same calculation but on the gpu\n",
        "  # First move tensors to gpu\n",
        "  x = x.to(\"cuda\")\n",
        "  y = y.to(\"cuda\")\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_gpu = time.time() - start_time\n",
        "  \n",
        "  print(\"Time on CPU: {:.5f}s \\t Time on GPU: {:.5f}s\".format(time_cpu, time_gpu))\n",
        "  print(\"Speed up: Computation was {:.0f}X faster on GPU!\".format(time_cpu / time_gpu))\n",
        "  \n",
        "else:\n",
        "  print(\"You need to enable GPU accelaration in colab (runtime->change runtime type)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time on CPU: 0.07276s \t Time on GPU: 0.00420s\n",
            "Speed up: Computation was 17X faster on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-AOzDy9lFwi"
      },
      "source": [
        "Comme prévu, la multiplication de matrice est beaucoup plus rapide sur un GPU, il est donc préférable de l'utiliser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0kqEBjG6t2Eh"
      },
      "source": [
        "\n",
        "# II. Entrainement d'un classifieur\n",
        "\n",
        "\n",
        "Pour ce tutoriel, nous allons utiliser le jeu de données CIFAR10.\n",
        "Il existe 10 classes: «avion», «automobile», «oiseau», «chat», «cerf»,\n",
        "«Chien», «grenouille», «cheval», «navire», «camion». Les images dans CIFAR-10 sont de taille 3x32x32, c’est-à-dire des images couleur à 3 canaux de 32x32 pixels.\n",
        "\n",
        "![CIFAR10](http://pytorch.org/tutorials/_images/cifar10.png)\n",
        "\n",
        "Nous allons faire les étapes suivantes dans l'ordre:\n",
        "\n",
        "1. Charger et normaliser les jeux de données d'entrainement et de test CIFAR10 à l’aide de `` torchvision``\n",
        "2. Définir un réseau de neurones de convolution\n",
        "3. Définir une fonction de perte\n",
        "4. Entrainer le réseau sur les données de d'entrainement\n",
        "5. Testez le réseau sur les données de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UWTdj2uYcax7"
      },
      "source": [
        "## 1. Charger and normaliser le dataset CIFAR10 \n",
        "\n",
        "Avec `` torchvision``, il est relativement facile de charger CIFAR10 a l'aide des fonctions fournies :\n",
        "* la fonction 'datasets.CIFAR10' chargent directement les données depuis un dépot public. Elles peuvent leur appliquer des transformations, ici une normalisation sur la place [-1,1].\n",
        "* les fonctions `sampler` permettent de prendre une partie des données (ici aléatoirement)\n",
        "* les `DataLoader` sont ensuite définis. Il permettront à l'algorithme d'apprentissage ou de test d'obtenir des données au format adapté (bonne taille de batch par exemple)\n",
        "\n",
        "Commençons par définir les `sampler` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DJdDop1IbEkL"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Define default device, we should use the GPU (cuda) if available\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "n_training_samples = 20000 # Max: 50 000 - n_val_samples\n",
        "n_val_samples = 5000\n",
        "n_test_samples = 5000\n",
        "\n",
        "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
        "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdE1HNqmbL0P"
      },
      "source": [
        "Ensuite, définissons les transformations à appliquer lors du chargement :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Z9jWm9frbMI-"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwP1_mdibg7L"
      },
      "source": [
        "Créons ensuite l'interface avec le dataset et les `Dataloader`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7DmJiRPbhUv"
      },
      "source": [
        "num_workers = 2\n",
        "test_batch_size = 4\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch_size, sampler=train_sampler,\n",
        "                                          num_workers=num_workers)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, sampler=test_sampler,\n",
        "                                         num_workers=num_workers)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cGWVnBOft2FI"
      },
      "source": [
        "Comme premier exemple d'utilisation des `Dataloader`, nous pouvons afficher des images aléatoires du dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "68OfC35ut2FM"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('{:>10}'.format(classes[labels[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8ULHEu5Zt2Fa"
      },
      "source": [
        "## 2. Definition d'un réseau de neurones convolutionnel\n",
        "\n",
        "Commençons par importer les modules utiles :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6k6rJyTTcayi"
      },
      "source": [
        "# Useful imports\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0JcmlEe8t2Fe"
      },
      "source": [
        "\n",
        "En PyTorch, des fonctions intégrées permettent de définir les différents éléments d'un réseau de convolution:\n",
        "\n",
        "- **nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1, padding = 0):** Couche de convolution. Vous pouvez lire la documentation complète [ici](http://pytorch.org/docs/master/nn.html#conv2d)\n",
        "\n",
        "- **nn.MaxPool2d(taille du noyau, stride = aucun, remplissage = 0):** Couche de max-pooling. Vous pouvez lire la documentation complète [ici](http://pytorch.org/docs/master/nn.html#maxpool2d)\n",
        "\n",
        "- **F.relu(Z1):** applique la fonction ReLU pour chaque élément de Z1 (qui peut être n’importe quelle forme). Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/nn.html#torch.nn.ReLU)\n",
        "\n",
        "- **x.view(new_shape)**: renvoie un nouveau tenseur avec les mêmes données mais une taille différente. C'est l'équivalent de la fonction numpy *reshape* (donne une nouvelle forme à un tableau sans changer ses données). Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "- **nn.Linear(in_features, out_features)**: Applique une transformation linéaire aux données entrantes: $y = Ax + b$, elle est également appelée  'couche entièrement connectée'. Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/nn.html#linear-layers)\n",
        "\n",
        "Nous allons maintenant définir un réseau simples, avec une chouche de convolution suivie d'un max pooling, une couche entièrement connectée et une couche de sortie:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "X4pljAWycayn"
      },
      "source": [
        "class SimpleConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvolutionalNetwork, self).__init__()\n",
        "        \n",
        "        # Initialize the network layers in the right order\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        # cf comments in forward() to have step by step comments\n",
        "        # on the shape (how we pass from a 3x32x32 input image to a 18x16x16 volume)\n",
        "        self.fc1 = nn.Linear(18 * 16 * 16, 64) \n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass,\n",
        "        x shape is (batch_size, 3, 32, 32)\n",
        "        (color channel first)\n",
        "        in the comments, we omit the batch_size in the shape\n",
        "        \"\"\"\n",
        "        # Here we define the operations that are required to compute the network output from the input data\n",
        "\n",
        "        # shape : 3x32x32 -> 18x32x32\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 18x32x32 -> 18x16x16\n",
        "        x = self.pool(x)\n",
        "        # 18x16x16 -> 4608\n",
        "        x = x.view(-1, 18 * 16 * 16)\n",
        "        # 4608 -> 64\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 64 -> 10\n",
        "        # The softmax non-linearity is applied later (cf createLossAndOptimizer() fn)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2SQi9Xf-t2Fu"
      },
      "source": [
        "## 3. Définition d'une fonction de cout et d'un optimiseur\n",
        "\n",
        "Nous utilisons une fonction de cout à base de cross-entropie pour la classification et ADAM. Vous pouvez en savoir plus sur les [méthodes d'optimisation](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DOUiPtZQt2Fx"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    # it combines softmax with negative log likelihood loss\n",
        "    criterion = nn.CrossEntropyLoss()  \n",
        "    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    return criterion, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "saJW5bKRt2F9"
      },
      "source": [
        "## 4. Entrainement du réseau\n",
        "\n",
        "Nous allons maintenant utiliser tous ces éléments pour réaliser l'entrainement. Pour cela, nous créons une fonction qui réalise une boucle qui utilise le `DataLoader`, applique le réseau sur les données obtenues, and optimise les poids afin de réduire la `loss` calculée.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yTDHHbLpcay5"
      },
      "source": [
        "### Définition de la fonction d'entrainement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dATbDR5pt2GE"
      },
      "source": [
        "def get_train_loader(batch_size):\n",
        "    return torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler,\n",
        "                                              num_workers=num_workers)\n",
        "\n",
        "# Use larger batch size for validation to speed up computation\n",
        "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler,\n",
        "                                          num_workers=num_workers)\n",
        "\n",
        "\n",
        "def train(net, batch_size, n_epochs, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a neural network and print statistics of the training\n",
        "    \n",
        "    :param net: (PyTorch Neural Network)\n",
        "    :param batch_size: (int)\n",
        "    :param n_epochs: (int)  Number of iterations on the training set\n",
        "    :param learning_rate: (float) learning rate used by the optimizer\n",
        "    \"\"\"\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"n_epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_minibatches = len(train_loader)\n",
        "\n",
        "    criterion, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    # Init variables used for plotting the loss\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "    best_error = np.inf\n",
        "    best_model_path = \"best_model.pth\"\n",
        "    \n",
        "    # Move model to gpu if possible\n",
        "    net = net.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        print_every = n_minibatches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Move tensors to correct device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # print every 10th of epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:    \n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                      epoch + 1, int(100 * (i + 1) / n_minibatches), running_loss / print_every,\n",
        "                      time.time() - start_time))\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "\n",
        "        train_history.append(total_train_loss / len(train_loader))\n",
        "\n",
        "        total_val_loss = 0\n",
        "        # Do a pass on the validation set\n",
        "        # We don't need to compute gradient,\n",
        "        # we save memory and computation using th.no_grad()\n",
        "        with th.no_grad():\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move tensors to correct device\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              predictions = net(inputs)\n",
        "              val_loss = criterion(predictions, labels)\n",
        "              total_val_loss += val_loss.item()\n",
        "            \n",
        "        val_history.append(total_val_loss / len(val_loader))\n",
        "        # Save model that performs best on validation set\n",
        "        if total_val_loss < best_error:\n",
        "            best_error = total_val_loss\n",
        "            th.save(net.state_dict(), best_model_path)\n",
        "\n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "\n",
        "    print(\"Training Finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
        "    \n",
        "    # Load best model\n",
        "    net.load_state_dict(th.load(best_model_path))\n",
        "    \n",
        "    return train_history, val_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl_H3BkdmoHz"
      },
      "source": [
        "### Entrainement\n",
        "\n",
        "Nous allons maintenant pouvoir lancer l'entrainement. Cela devrait prendre une dizaine de secondes par époque :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cJX2anB5cay_"
      },
      "source": [
        "net = SimpleConvolutionalNetwork()\n",
        "\n",
        "train_history, val_history = train(net, batch_size=32, n_epochs=3, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UkVKNPtccazC"
      },
      "source": [
        "### Visualisation de l'évolution de la `loss`\n",
        "\n",
        "Nous pouvons mainentant visualiser l'évolution des pertes d'entrainement et de validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4CUQt-HJcazF"
      },
      "source": [
        "plot_losses(train_history, val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "O90WcUTwt2GU"
      },
      "source": [
        "## 5. Test du réseau sur les données de test\n",
        "\n",
        "\n",
        "Nous avons entrainé le réseau pour 3 passages sur l'ensemble de données d'apprentissage. Mais nous devons vérifier si le réseau a appris quelque chose.\n",
        "\n",
        "Nous allons vérifier cela en prédisant l'étiquette de classe donnée par le réseau de neurones, et la comparer à la vérité sur le terrain. Si la prédiction est correct, nous ajoutons l'échantillon à la liste des prédictions correctes.\n",
        "\n",
        "Commençons par charger et afficher les données de test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "V4vljwBlt2GX"
      },
      "source": [
        "try:\n",
        "  images, labels = next(iter(test_loader))\n",
        "except EOFError:\n",
        "  pass\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(\"Ground truth:\\n\")\n",
        "\n",
        "print(' '.join('{:>10}'.format(classes[labels[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KpmaQT4Zt2Gn"
      },
      "source": [
        "### Résultats sur les données de test\n",
        "\n",
        "Voyons maintenant les prédiction du réseau pour ces images. Les sorties correspondent aux probabilités de chacune des 10 classes. Il faut donc chercher la classe de plus forte probabilité:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IWTWHHs9t2G5"
      },
      "source": [
        "outputs = net(images.to(device))\n",
        "print(outputs.size())\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print(\"Predicted:\\n\")\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print(' '.join('{:>10}'.format(classes[predicted[j]]) for j in range(test_batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AUpCEAOTt2HK"
      },
      "source": [
        "### Performances en précision\n",
        "\n",
        "Voyons comment le réseau fonctionne sur l’ensemble des tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LI6JtYwTt2HM"
      },
      "source": [
        "def dataset_accuracy(net, data_loader, name=\"\"):\n",
        "    net = net.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    accuracy = 100 * float(correct) / total\n",
        "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n",
        "\n",
        "def train_set_accuracy(net):\n",
        "    dataset_accuracy(net, train_loader, \"train\")\n",
        "\n",
        "def val_set_accuracy(net):\n",
        "    dataset_accuracy(net, val_loader, \"validation\")  \n",
        "    \n",
        "def test_set_accuracy(net):\n",
        "    dataset_accuracy(net, test_loader, \"test\")\n",
        "\n",
        "def compute_accuracy(net):\n",
        "    train_set_accuracy(net)\n",
        "    val_set_accuracy(net)\n",
        "    test_set_accuracy(net)\n",
        "    \n",
        "print(\"Computing accuracy...\")\n",
        "compute_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iGGyra-4t2HW"
      },
      "source": [
        "Les performances sur l’ensemble de test des images sont nettement meilleures que le hasard, qui correspond à une précision de 10% (sélection aléatoire d'une classe sur 10 classes). Pour information, un modèle linéaire atteint une précision d'environ 30%.\n",
        "\n",
        "Nous pouvons ensuite regarder quelles sont les classes qui ont été bien reconnues ou non, et calculer les données de la matrice de confusion au passage :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rkim9_INt2HY"
      },
      "source": [
        "def accuracy_per_class(net):\n",
        "    net = net.to(device)\n",
        "    n_classes = 10\n",
        "    # (real, predicted)\n",
        "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        for i in range(test_batch_size):\n",
        "            confusion_matrix[labels[i], predicted[i]] += 1\n",
        "            label = labels[i]\n",
        "\n",
        "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n",
        "    for i in range(n_classes):\n",
        "        class_total = confusion_matrix[i, :].sum()\n",
        "        class_correct = confusion_matrix[i, i]\n",
        "        percentage_correct = 100.0 * float(class_correct) / class_total\n",
        "        \n",
        "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\n",
        "    return confusion_matrix\n",
        "\n",
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AZKLymOacazg"
      },
      "source": [
        "### Visualisation de la matrice de Confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ekJHz3vpcazg"
      },
      "source": [
        "Regardons quel type d'erreur faite notre réseau.\n",
        "Il semble que notre réseau est assez bon pour classer les navires,\n",
        "mais a quelques difficultés à différencier les chats et les chiens.\n",
        "En outre, beaucoup de camions sont classés comme des voitures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1aYMqD1Ocazi"
      },
      "source": [
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix, classes, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix, classes,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MVv-mV8Pt2Hs"
      },
      "source": [
        "# III. Exploration des architectures de CNN\n",
        "\n",
        "Maintenant, c'est à votre tour de construire un réseau de neurones convolutionnels. L'objectif de cette section est d'explorer différentes architectures CNN et de définir des hyperparamètres afin d'obtenir la meilleure précision possible sur l'ensemble de **test** !\n",
        "\n",
        "Le réseau que vous devez modifier s'appelle **MyConvolutionalNetwork**.\n",
        "\n",
        "Vous pouvez commencer à modifier la valeur batch_size, le nombre d'époques, la taille du test et d el'entrainement, puis essayer d'ajouter d'autres couches de convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "h1blK9eicazo"
      },
      "source": [
        "## Rappel des fonctions PyTorch utiles\n",
        "\n",
        "Nous rappelons ici les fonctions utiles pour définir un réseau :\n",
        "\n",
        "- **nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1, padding = 0):** Couche de convolution. Vous pouvez lire la documentation complète [ici](http://pytorch.org/docs/master/nn.html#conv2d)\n",
        "\n",
        "- **nn.MaxPool2d(taille du noyau, stride = aucun, remplissage = 0):** Couche de max-pooling. Vous pouvez lire la documentation complète [ici](http://pytorch.org/docs/master/nn.html#maxpool2d)\n",
        "\n",
        "- **F.relu(Z1):** applique la fonction ReLU pour chaque élément de Z1 (qui peut être n’importe quelle forme). Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/nn.html#torch.nn.ReLU)\n",
        "\n",
        "- **x.view(new_shape)**: renvoie un nouveau tenseur avec les mêmes données mais une taille différente. C'est l'équivalent de la fonction numpy *reshape* (donne une nouvelle forme à un tableau sans changer ses données). Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/tensors.html#torch.Tensor.view)\n",
        "\n",
        "- **nn.Linear(in_features, out_features)**: Applique une transformation linéaire aux données entrantes: $y = Ax + b$, elle est également appelée  'couche entièrement connectée'. Vous pouvez lire la documentation complète [ici.](http://pytorch.org/docs/master/nn.html#linear-layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "a8-lKBaacazp"
      },
      "source": [
        "### Formules de convolution\n",
        "\n",
        "Pour vous aider, voici les formules reliant la taille de sortie $(C_2, H_2, W_2)$ d'une couche de convolution dont l'entrée est de taille $(C_1, H_1, W_1)$ :\n",
        "\n",
        "\n",
        "$$ H_2 = \\lfloor \\frac{H_1 - kernel\\_size + 2 \\times padding}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ W_2 = \\lfloor \\frac{W_1 - kernel\\_size + 2 \\times padding}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ C_2 = \\text{number of filters used in the convolution}$$\n",
        "\n",
        "NOTE: $C_2 = C_1$ pour le max pooling\n",
        "\n",
        "avec:\n",
        "- $H_2$: hauteur  \n",
        "- $W_2$: largeur\n",
        "- $C_1$: nombre de canaux d'entrée\n",
        "- $C_2$: nombre de canaux de sortie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "acppf3nkcazr"
      },
      "source": [
        "def get_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    \"\"\"\n",
        "    Get the output size given all the parameters of the convolution\n",
        "    :param in_size: (int) input size\n",
        "    :param kernel_size: (int)\n",
        "    :param stride: (int)\n",
        "    :param paddind: (int)\n",
        "    :return: (int)\n",
        "    \"\"\"\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SEsbZoTOcazu"
      },
      "source": [
        "Exemple d'utilisation de get_output_size() : Supposons que vous avez un *tenseur d'entrée de taille 3x32x32* (où 3 est le nombre de canaux) et vous utilisez une convolution 2D avec les paramètres suivants:\n",
        "```python\n",
        "conv1 = nn.Conv2d(3, 18, kernel_size=7, stride=2, padding=1)\n",
        "```\n",
        "alors, la taille du volume de sortie est 18 x ? x ? (parce que nous avons 18 filtres) où ? est donnée par les formules de convolution (voir ci-dessus).\n",
        "**get_output_size()** permet de calculer cette valeur :\n",
        "\n",
        "```\n",
        "out_size = get_output_size(in_size=32, kernel_size=7, stride=2, padding=1)\n",
        "print(out_size) # prints 14\n",
        "```\n",
        "\n",
        "Le couche de sortie est donc de taille 18x14x14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2JFQ1wgKcazv"
      },
      "source": [
        "out_size = get_output_size(in_size=32, kernel_size=7, stride=2, padding=1)\n",
        "print(out_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wviV5iQIcazz"
      },
      "source": [
        "## Définition et entrainement de votre réseau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpLudl9m2IYr"
      },
      "source": [
        "\n",
        "### Définiton du réseau\n",
        "\n",
        "Voici le réseau que vous pouvez modifier. Il est pour le moment constitué d'une seule couche de convolution, d'une couche de pooling et d'un couche entièrement connectée :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fnKUPUDTcaz1"
      },
      "source": [
        "class MyConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyConvolutionalNetwork, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        #### START CODE: ADD NEW LAYERS ####\n",
        "        # (do not forget to update `flattened_size`:\n",
        "        # the input size of the first fully connected layer self.fc1)\n",
        "        # self.conv2 = ...\n",
        "        \n",
        "        # Size of the output of the last convolution:\n",
        "        self.flattened_size = 18 * 16 * 16\n",
        "        ### END CODE ###\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass,\n",
        "        x shape is (batch_size, 3, 32, 32)\n",
        "        (color channel first)\n",
        "        in the comments, we omit the batch_size in the shape\n",
        "        \"\"\"\n",
        "        # shape : 3x32x32 -> 18x32x32\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 18x32x32 -> 18x16x16\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        #### START CODE: USE YOUR NEW LAYERS HERE ####\n",
        "        # x = ...\n",
        "        \n",
        "        #### END CODE ####\n",
        "        \n",
        "        # Check the output size\n",
        "        output_size = np.prod(x.size()[1:])\n",
        "        assert output_size == self.flattened_size,\\\n",
        "                \"self.flattened_size is invalid {} != {}\".format(output_size, self.flattened_size)\n",
        "        \n",
        "        # 18x16x16 -> 4608\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        # 4608 -> 64\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 64 -> 10\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqwJl6kLuAwc"
      },
      "source": [
        "### Entrainement\n",
        "\n",
        "Vous pouvez ensuite l'entrainer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": false,
        "id": "ruLWyTSocaz5"
      },
      "source": [
        "net = MyConvolutionalNetwork()\n",
        "train_history, val_history = train(net, batch_size=32, n_epochs=10, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "u7cgVbkDcaz9"
      },
      "source": [
        "### Affichage de la `Loss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XtXu67qbcaz-"
      },
      "source": [
        "plot_losses(train_history, val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TuGKgAMWcaz_"
      },
      "source": [
        "### Précision du modèle\n",
        "\n",
        "Pour mémoire, le réseau défini dans la partie II avait une performance autour de 60%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TWowqQhYca0B"
      },
      "source": [
        "compute_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OKvmb4p-ca0I"
      },
      "source": [
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ih5Pj0WBca0L"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix, classes,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7xzIkZqit2IA"
      },
      "source": [
        "# Pour aller plus loin\n",
        "\n",
        "- [Coursera Course on CNN](https://www.coursera.org/learn/convolutional-neural-networks)\n",
        "- [Standford Course](http://cs231n.stanford.edu/syllabus.html)\n",
        "- [PyTorch Tutorial](http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        "\n",
        "\n",
        "\n",
        "Remarque: Ce tutoriel est basé sur le [tutoriel original de PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) et a été adapté par [Antonin Raffin](http://araffin.github.io) et David Filliat. "
      ]
    }
  ]
}