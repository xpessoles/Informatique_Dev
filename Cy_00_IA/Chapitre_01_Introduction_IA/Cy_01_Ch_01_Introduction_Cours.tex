%%%% Paramétrage du cours %%%%
\def\xxactivite{Cours}
\def\xxauteur{\textsl{Xavier Pessoles \& Anthony Meurdefroid}}

\fichefalse
\proftrue
\tdfalse
\courstrue

\def\xxnumchapitre{Chapitre 1 \vspace{.2cm}}
\def\xxchapitre{\hspace{.12cm} Introduction}

\def\xxcompetences{%
\textsl{%
\textbf{Savoirs et compétences :}\\
\begin{itemize}[label=\ding{112},font=\color{ocre}] 
\item Analyser les principes d'intelligence artificielle.
\begin{itemize}
\item Régression et classification, apprentissages supervisé et non supervisé.
\item Phases d'apprentissage et d'inférence.
\item Modèle linéaire monovariable ou multivariable.
\item Réseaux de neurones (couches d'entrée, cachées et de sortie, neurones, biais, poids et fonction d'activation).
\end{itemize}
\item Interpréter et vérifier la cohérence des résultats obtenus expérimentalement, analytiquement : Ordre de grandeur. Matrice de confusion (tableau de contingence), sensibilité et spécificité d'un test.
\item Résoudre un problème en utilisant une solution d'intelligence artificielle : 
\begin{itemize}
\item Apprentissage supervisé.
\item Choix des données d'apprentissage. 
\item Mise en œuvre des algorithmes (réseaux de neurones, $k$ plus proches voisins et régression linéaire multiple).
\item Phases d'apprentissage et d'inférence.
\end{itemize}
%\item \textit{Mod2.C17} : torseur dynamique
%\item \textit{Mod2.C17.SF1} : déterminer le torseur dynamique d’un solide, ou d’un ensemble de solides, par rapport à un autre solide
%\item \textit{Mod2.C15} : matrice d'inertie
%\item \textit{Res1.C2} : principe fondamental de la dynamique
%\item \textit{Res1.C1.SF1} : proposer une démarche permettant la détermination de la loi de mouvement
%\item \textit{Res1.C2.SF1} : proposer une méthode permettant la détermination d’une inconnue de liaison
\end{itemize}
}}



\def\xxfigures{
}%figues de la page de garde

\iflivret
\input{../../style/new_pagegarde}
\else
\input{../../style/new_pagegarde}
\fi
\setlength{\columnseprule}{.1pt}

\vspace{2cm}
\pagestyle{fancy}
\thispagestyle{plain}








\section{L'Intelligence Artificielle, qu'est ce que c'est, à quoi ça sert ?}

\subsection{Premières définitions -- IA, données}
%\subsection{Première approche. Que veut-on ? Qu'obtient-on ?}
\begin{defi}[Intelligence Artificielle]
Wikipedia -- L'intelligence artificielle (IA) est « l'ensemble des théories et des techniques mises en œuvre en vue de réaliser des machines capables de simuler l'intelligence ». 
\end{defi}

En première approche, l'IA peut être assimilée à un ensemble d'algorithmes permettant de réaliser des tris, des classifications.
\begin{exemple}~\\
\\
\vspace{-1cm}

\begin{multicols}{2}
\begin{center}
\includegraphics[width=.8\linewidth]{fig_01}
\end{center}
Identification d'objets, en temps réel, dans une vidéo.

\begin{center}
\includegraphics[width=.95\linewidth]{fig_02_a}
\end{center}


Comparaison du résultats d'algorithmes de classification permettant de classifier un nuage de points bleus et rouges de transparences différentes.
\end{multicols}

On remarquera sur l'exemple de gauche que l'algorithme parvient à identifier sur l'image des zones puis à identifier à quoi elles correspondent. On remarquera aussi que la flamme est identifiée comme étant un donut...


\begin{flushright}
\footnotesize
\url{exploring-opencvs-deep-learning-object-detection-library} \&  \url{https://scikit-learn.org/}.
\normalsize

\end{flushright}
\end{exemple}



Pour utiliser un algorithme d'IA il est nécessaire de disposer de données... en général beaucoup de données. 
\begin{defi}[Données]
Les données utilisées par un algorithme d'IA peuvent être sous différentes formes : 
\begin{itemize}
\item des données quantitatives continues qui peuvent prendre n'importe quelles valeurs dans un ensemble de valeurs (par exemple la température);
\item des données quantitatives discrètes qui peuvent prendre un nombre limité de valeurs dans un ensemble de valeurs (par exemple nombre de pièces d'un logement);
\item des données qualitatives (ordinales ou nominales suivant qu'on puissent les classer ou non, par exemple des couleurs, des notes à un test d'opinion ...).
\end{itemize}

\end{defi}

Pour pouvoir traiter ces données, il peut être nécessaire qu'elles soient organisées sous une certaine forme. On peut par exemple identifier : 
\begin{itemize}
\item les données structurées, dans une base de données par exemple;
\item les données semi-structurées, dans un fichier csv, xml ou json par exemple;
\item les données non structurées comme un image, du texte, ou une vidéo.
\end{itemize}

\begin{exemple}
\end{exemple}

\begin{defi}[Observations -- Caractéristiques]

On appelle observation (ou individu ou objet) une << ligne de donnée >> qui va être utilisée par un algorithme d'apprentissage. 

Une observation est composée de caractéristiques qui varient pour chacun des observations. 
\end{defi}

\begin{exemple}~\\

\begin{minipage}[c]{.65\linewidth}
Dans le cas de la base de donnée des Iris, présente par exemple dans \texttt{scikit-learn}, les données sont composées de 150 observations, chacune composée de 4 caractéristiques : longueur et largeur du sépale ainsi que longueur et largeur du pétale.
\end{minipage} \hfill
\begin{minipage}[c]{.3\linewidth}
\begin{center}
\includegraphics[width=.6\linewidth]{fig_10}
\end{center}
\end{minipage} 

\end{exemple}


\begin{defi}[Big data -- Wikipedia]
Mégadonnées ou données massives. Le big data désigne les ressources d’informations dont les caractéristiques en termes de volume, de vélocité et de variété imposent l’utilisation de technologies et de méthodes analytiques particulières pour générer de la valeur, et qui dépassent en général les capacités d'une seule et unique machine et nécessitent des traitements parallélisés.
\end{defi}




Que fait-on avec ces données ? En général les algorithmes vont chercher un lien entre ces données. Dans le cas où il existe un lien connu par le \textit{Data Scientist} on parle d'apprentissage supervisé. 

Si ce lien n'est pas connu, on parle d'apprentissage non supervisé ou de clustering. 


\subsection{Apprentissage automatisé -- Machine Learning}



\begin{defi}[Apprentissage automatique -- Machine learning]
L'apprentissage automatique est un champ de l'intelligence artificielle dont l'objectif est d'analyser un grand volume de
données afin de déterminer des motifs et de réaliser un modèle prédictif. 

L'apprentissage comprend deux phases : 
\begin{itemize}
\item l’entraînement (ou apprentissage) est une phase d'estimation du modèle à partir de données d'observations; 
\item la mise en production du modèle (inférence) est une phase pendant laquelle de nouvelles données sont traitées dans le but d'obtenir le résultat souhaité. 
\end{itemize}

L’entraînement peut être poursuivi même en phase de production.

\end{defi}


\begin{exemple}~\\

\begin{center}
\includegraphics[width=.6\linewidth]{fig_05}
\end{center}
\end{exemple}


\begin{defi}[Apprentissage supervisé -- Apprentissage]
Tâche d'apprentissage au cours duquel l'algorithme (ou fonction de prédiction) va, à partir d'un ensemble de données \textbf{étiquetées}, déterminer un lien entre un ensemble les données et les étiquettes. 
\end{defi}

\begin{defi}[Apprentissage supervisé -- Inférence]
Tâche au cours duquel l'algorithme (ou fonction de prédiction) va, à partir d'un ensemble de données \textbf{non étiquetées}, prédire l'étiquette.

\end{defi}



\begin{exemple}~\\

\begin{center}
\includegraphics[width=.8\linewidth]{fig_06}
\end{center}
\end{exemple}


\begin{exemple}
Soit un ensemble d'images en noir et blanc représentant des chiffres de 0 à 9. L'algorithme doit dans un premier temps \textit{apprendre} le lien entre l'image et le chiffre. 
Dans un second temps, l'algorithme devra déterminer le chiffre en fonction d'une image seule.
\end{exemple}

\begin{defi}[Apprentissage non supervisé -- Clustering]
Tâche d'apprentissage au cours duquel l'algorithme (ou fonction de prédiction) va, à partir d'un ensemble de données \textbf{non étiquetées}, déterminer un lien entre les données (et les regrouper). 
\end{defi}



\begin{exemple} ~\\


\begin{center}
\includegraphics[width=.8\linewidth]{fig_07}
\end{center}


Classification d'iris en utilisant un algorithme d'apprentissage non supervisé.
\begin{center}
\includegraphics[width=.8\linewidth]{fig_03}
\end{center}

On remarque (lorsque l'image est en couleur) que sur des mesures sur 150 iris, l'algorithme a réussi à retrouver les 3 différentes espèces, sans les connaître, à 3 erreurs près.

\end{exemple}


\begin{defi}[Apprentissage par renforcement]
Si au cours de l'apprentissage supervisé, un mécanisme de récompense est mis en \oe{}uvre pour améliorer les performances du modèle, on parle d'apprentissage par renforcement.
\end{defi}



On peut donc faire une synthèse des méthodes d'apprentissage dont nous avons pris connaissance (il en existe d'autres).

\begin{center}
\includegraphics[width=.8\linewidth]{fig_08}
\end{center}

\textit{Comment situer le deep learning parmi ces méthodes d'apprentissage ? --  Pour moi, XP,  l'utilisation du terme << deep learning >> apparaît lorsqu'on commence à utiliser des réseaux de neurones... mais les réseaux de neurones peuvent être utilisés dans chacune des méthodes d'apprentissage sus-citées...}

\subsection{Encore des définitions...}

\begin{defi}[Classification]
En apprentissage automatique, on appelle problème de classification les problèmes ou les étiquettes sont discrètes.
\end{defi}

\begin{exemple} ~\\

\begin{center}
\includegraphics[width=.8\linewidth]{fig_06}
\end{center}

Dans le cas où nous souhaitons regrouper par forme, il s'agit d'un problème de classification. Les classes discrètes sont les formes (triangles, carrés, pentagones ...). 

Il serait aussi possible d'opérer un regroupement par couleur. Les classes seraient donc différentes.
\end{exemple}

\begin{defi}[Régression]
En apprentissage automatique, on appelle problème de régression les problèmes ou les étiquettes sont continues.
\end{defi}

\begin{exemple}
Dans le cas où nous souhaiterions que l'algorithme détermine l'aire ou le périmètre de la forme, les étiquette seraient alors continues sur $\mathbb{R}^{+}_{*}$.

\end{exemple}


\section{Mécanismes d'apprentissages}

\subsection{Classification des algorithmes d'apprentissage}

La bibliothèque \texttt{scikit-learn} propose une classification de divers algorithmes en fonction des apprentissages automatiques (hors réseaux de neurones).


\begin{center}
\includegraphics[width=\linewidth]{fig_09}
\end{center}


\subsection{Validation du modèle}
Une fois un algorithme d'apprentissage choisi, on se pose la question de la validation du modèle. Quels critères et outils vont nous permettre de considérer que notre apprentissage est << bon >> ?

Lors d'un problème de classification, il est par exemple possible de déterminer les écarts entre les valeurs prédites par l'algorithme et les valeurs cibles.

\subsubsection{Critères de validation des problèmes de classification}



\begin{defi}[Valeur prédictive positive]
Valeur prédictive positive (\textit{accuracy classification score})
$$
\text{Précision} = \dfrac{\text{Nombre de prédictions vraies}}{\text{Nombre de prédictions totales}}
$$
\end{defi}

\begin{lstlisting}
import sklearn.metrics as skm

# X(numpy.ndarray) : données d'entrées
# Y(numpy.ndarray) : données cibles correspondantes
# Y_pred(numpy.ndarray) : données prédites par l'algorithme de classification

print(skm.accuracy_score(Y, Y_pred))
\end{lstlisting}



\begin{defi}[Matrices de confusion]

\end{defi}

\subsubsection{Critères de validation des problèmes de régression}

\subsubsection{Critères de validation des problèmes d'apprentissage non supervisé}

\subsection{Données et séparation des données/Gestion des données ?}
Lorsque l'on souhaite disposer d'un modèle défini par un algorithme d'IA, il faut en premier lieu disposer de données. 

\subsubsection{Types de données -- Apprentissage supervisé}

En apprentissage supervisé, il est nécessaire de connaître des données d'entrées ainsi que les sorties correspondantes (appelées aussi \texttt{cibles} ou \texttt{target}).

Dans le cadre d'une programmation \texttt{Python} avec la bibliothèque \texttt{scikit-learn} les données d'entées et de sorties peuvent être implémentées en utilisant des \texttt{numpy.ndarray}.

Ainsi, si les données d'entrées, stockées dans la variable \texttt{data} sont composées de \texttt{n} observations elles mêmes composées de \texttt{p} catégories, le \text{shape} de \texttt{data} sera \texttt{(n,p)}.

La donnée cible sera quant à elle un vecteur de \texttt{n} valeurs. 

\begin{exemple}~\\

Données d'entrées  : matrice  \texttt{X} de \texttt{n} observations avec 4 caractéristiques. 

Données de sortie : vecteur \texttt{Y} de \texttt{n} résultats. 
\begin{center}
\includegraphics[width=.5\linewidth]{fig_11}
\end{center}

Dans le cadre d'une classification, où \texttt{r} résultats sont possibles. On peut attribuer une valeur (entière) entre 1 et \texttt{r} à chacun des résultats, notamment si ceux-ci sont des données qualitatives.

\textcolor{red}{\textbf{Problème de l'identification d'un système : quelles sont les données d'entrées ? Quelles sont surtout les données de sorties ? Un vecteur aussi ?}}

\end{exemple}


\subsubsection{Normalisation des données}

\url{https://scikit-learn.org/stable/modules/preprocessing.html}

\subsubsection{Séparation des données}

Lors du démarrage d'un apprentissage supervisé, on dispose d'un jeu de données comprenant les données d'entrée et les cibles correspondantes. Il est d'usage de séparer ces données en deux parties :
\begin{itemize}
\item les données d’entraînement permettant... d’entraîner le modèle. Dans la pratique on utilise entre 60 et 80\,\% des données de base;
\item les données de te test, permettant de valider l'apprentissage (ou le modèle), dans la pratique entre 20 et 40\,\% des données de base.
\end{itemize}

On commence donc par réaliser un apprentissage sur les données d’entraînement. Cet entraînement produit des résultats. Connaissant les cibles correspondant aux données d'entraînement, on peut donc en déduire une performance du modèle sur le traitement des données d’entraînement. 

On utilise alors le modèle en lui donnant les données de test. De même, on peut donc en déduire une performance du modèle sur le traitement des données de test.  

\begin{center}
\includegraphics[width=.8\linewidth]{fig_12}
\end{center}

 Se pose alors le problème de comment séparer les données. En effet, les données de base pouvant potentiellement être triées (ordonnées par rapport à une des caractéristiques), et sélectionner une partie pourrait créer un biais dans l'apprentissage. 

\texttt{scikit-learn} permet de séparer aléatoirement des données en fixant le pourcentage de données de validation.


\begin{lstlisting}
from sklearn.model_selection import train_test_split
# X(numpy.ndarray) : données d'entrées
# Y(numpy.ndarray) : données cibles correspondantes
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)
\end{lstlisting}


On perçoit donc que la qualité de l'apprentissage peut dépendre du choix utilisé lors de la séparation des données. De plus, certains choix de paramètres permettant d’affiner le modèle sont aussi liés aux données d’entraînement sélectionnées. 
Une des solutions pour résoudre ce problème est d'avoir recours à la validation croisée. 

\textcolor{red}{\textbf{À creuser}}

%Il est parfois possible de séparer en faisant en sorte que les valeurs moyennes et écarts types des données cibles des données d’entraînement et des données de test soient les mêmes.

%La séparation des donné
%Afin de palier ce problème il est possible (conseillé) d'avoir recours à la validation croisée.  

\url{https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation}


%%%%
%\url{https://jonchar.net/notebooks/k-means/#:~:text=k%2Dmeans%20clustering%3A%20An%20example,3%20using%20numpy%20and%20matplotlib.&text=The%20k%2Dmeans%20algorithm%20is,user%20before%20starting%20the%20algorithm}

%\newpage

\section{Algorithmes d'apprentissage}
%
%\section{Réseaux de neurones}
%
%\url{https://playground.tensorflow.org/}
%
%
%
%\section{Définitions}
%
%\begin{itemize}
%\item Data scientist
%\item machine learning
%\item deep learning
%\item réseaux de neurons
%\item régression
%\item data mining
%\item bigdata
%\item données continues, données discrètes, données nominales, données ordinales, données (semi-)structurées et non structurées
%
%\end{itemize}
%
%
%\begin{itemize}
%\item algorithmes supervisés, non supervisés
%\item algorithmes de régression et de classification
%\end{itemize}
%
%\begin{defi}[Machine Learning -- Apprentissage automatique -- Wikipedia] 
%Champ d'étude de l'intelligence artificielle qui se fonde sur des approches mathématiques et statistiques pour donner aux ordinateurs la capacité d' « apprendre » à partir de données, c'est-à-dire d'améliorer leurs performances à résoudre des tâches sans être explicitement programmés pour chacune. 
%
%La première phase de l'apprentissage consiste à estimer un modèle à partir de données, appelées observations, qui sont disponibles et en nombre fini, lors de la phase de conception du système.
%
% La seconde phase correspond à la mise en production : le modèle étant déterminé, de nouvelles données peuvent alors être soumises afin d'obtenir le résultat correspondant à la tâche souhaitée.
%\end{defi}
%
%
%\begin{defi}[Apprentissage supervisé -- Apprentissage non supervisé -- Apprentissage par renforcement -- Wikipedia] 
%Si les données sont étiquetées (c'est-à-dire que la réponse à la tâche est connue pour ces données), il s'agit d'un apprentissage supervisé. On parle de :
%\begin{itemize}
%\item classification ou de classement si les étiquettes sont discrètes;
%\item régression si elles sont continues.
%\end{itemize}
%
%Si le modèle est appris de manière incrémentale en fonction d'une récompense reçue par le programme pour chacune des actions entreprises, on parle d'apprentissage par renforcement. 
%
%Dans le cas le plus général, sans étiquette, on cherche à déterminer la structure sous-jacente des données (qui peuvent être une densité de probabilité) et il s'agit alors d'apprentissage non supervisé.
%
%
%
%\end{defi}
%
%
%
%\subsection{Quelques définitions}
%\begin{defi}{Intelligence Artificielle, première approche}
%
%\end{defi}
%
%\subsection{Le nerf de la guerre, les données}
%
%
%
%\subsection{Méthode de résolution de problèmes d'apprentissage supervisé}
%
%\begin{enumerate}
%\item Choix des données.
%\item Normalisation des données. 
%\item Séparation des données ? (entraînement, test, validation)
%\item Choix de la méthode d’entraînement (choix d'un modèle, en fonction du type de données, choix des paramètres du modèle)
%\item Entraînement du modèle
%\item Test du modèle
%\item Observation des métriques et visualisation des résultats
%\end{enumerate}
%
%\section{Méthode de résolution d'un }
%
%\newpage
%
%
%1 cours Sur les réseau de neurones
%
%\section{TP : Synthèse d'un contrôleur piloté par réseau de neurones}
%
%TP identification de la boucle ouverte  
%\begin{itemize}
%\item Comparaison modèle (a)causal / réel
%\item Comparaison modèle ANN / réel
%\end{itemize}
%
%
%TP Synthèse du contrôleur PID 
%à partir du modèle
%To do XP
%
%TP synthèse du contrôleur et implémentation sur une cible. 
%Déploiement sur control X ?
%
%
%
%\newpage
%
%
%\newpage

Exemples : 
\url{https://makina-corpus.com/blog/metier/2017/initiation-au-machine-learning-avec-python-pratique}

\begin{thebibliography}{2}
   \bibitem[1]{ref1} Éric Biernat et Michel Lutz. {\it Data science : fondamentaux et études de cas.} Eyrolles.
\end{thebibliography}

